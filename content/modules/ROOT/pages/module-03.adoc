= Section 4 - Event Driven Ansible

What is Event-Driven Ansible‚ùì 
üì° Event-Driven Ansible (EDA) is an automation capability that listens for events in your IT environment‚Äîlike system alerts, security warnings, or network issues‚Äîand automatically triggers predefined actions in response. Instead of running tasks on a schedule, EDA uses "if-this-then-that" logic defined in Ansible Rulebooks to react to situations in real time.

How does EDA create a feedback loop (Observe, Evaluate, Respond)‚ùì
EDA works by creating a continuous, automated feedback loop that mirrors the Observe-Evaluate-Respond model:

image::eda.png[EDA, 150%]

*Observe*: It constantly listens to event sources like monitoring tools (e.g., Prometheus, Datadog) or security systems for notifications about the state of your infrastructure.

*Evaluate*: When an event is received, an Ansible Rulebook instantly evaluates it against a set of rules to determine what needs to be done.

*Respond*: Based on the decision, it automatically executes an action, such as running an Ansible Playbook to fix the problem, update a system, or send a notification.

*Key Applications*: Ticket Triage & Self-Healing Networks
This automated loop directly enables advanced IT operations:

*Automated Ticket Triage*: EDA can catch an alert, automatically run diagnostics, and then create a service desk ticket that is already enriched with all the necessary information, drastically reducing manual effort and response times.

*Self-Healing Networks*: When a network monitoring tool detects a problem like a failed link, EDA can immediately trigger a playbook to re-route traffic and restore service without any human intervention, creating a resilient, self-healing system.

In short, üì° Event-Driven Ansible connects your tools, codifies your operational knowledge into rules, and automates your response to create faster, more reliable, and more efficient IT operations.

== ‚öôÔ∏è Event Driven Ansible Setup

Earlier we configured a Splunk alert, now we need to configure Event Driven Ansible to receive the splunk alert as a webhook.

=== Accessing EDA
[cols="2,2", options="header"]
|===
| Component
| Value

| Username
| lab-user

| Password
| `{ssh_password}`
|===

Step 1: Open EDA from the AAP tab

image::bastion2.png[AAP]

Step 2: Navigate to "Automation Decisions" / "infrastructure" / "Credentials"

image::automation_decisions.png[automation decisions, 100%]

Step 3: Create a new credential of type "source control" called "gitea"

name == gitea

credential type == source control

organization == Default

user == lab-user

password == `{ssh-password}`

image::gitea_eda_credential.png[gitea cred,100%]

Step 4: Add the new project called "lightspeed"

image::createproject.png[Create Project,100%]

Step 5: Configure the project as follows and validate that the git repository syncs properly:

=== Project Settings
[cols="2,2", options="header"]
|===
| Component
| Value

| Name
| lightspeed

| Organization
| Default

| Source control type
| Git

| Source control URL
| https://{targethost}:{gitea_web_ui_port}/lab-user/lightspeed_playbooks.git

| Source control credential
| gitea

|===

image::validate_sync.png[Validate Sync,150%]

Step 6: Create a "rulebook activation"

image::create_rulebook_activation.png[create rulebook activation, 100%]

Configure the rulebook activation as follows:

=== Rulebook Activation
[cols="2,2", options="header"]
|===
| Component
| Value

| Name
| ospf-neighbor

| Organization
| Default

| Project
| lightspeed

| Rulebook
| ospf.yml

| Credential
| gitea

| Decision environment
| Kafka Decision Environment

| log level
| Debug

|===

image::rulebook_activation.png[Rulebook Activation, 150%]

Step 7: Verify Rulebook Activation

Make sure the ospf-neighbor rulebook activation is running.

image::rulebook_validate.png[rulebook validate, 150%]

Step 8: Review the Rulebook `ospf.yml`

[source, YAML]
----
---
- name: "Listen for OSPF neighbor events on a webhook"
  hosts: all

  sources:
    - name: "Webhook listener for OSPF events"
      ansible.eda.webhook:
        host: 0.0.0.0
        port: 5000

  rules:
    - name: "Process OSPF neighbor event from webhook"
      condition: event.payload.search_name == 'ospf-neighbor'
      actions:
        - debug:
            msg: |
              ‚úÖ OSPF Webhook Received!
              Search Name: {{ event.payload.search_name }}
              Triggering workflow...

        - run_workflow_template:
            name: "Network-AIOps-Workflow"
            organization: "Default"
            job_args:
              extra_vars:
                webhook_payload: "{{ event.payload }}"
----
This Event-Driven Ansible rulebook uses a webhook source plugin to listen for events on TCP port 5000. Its rule is configured to trigger an activation only when an incoming event payload contains the exact key-value pair of 'search_name': 'ospf-neighbor', which corresponds to the Splunk event configuration from the previous module. When this condition is met, the primary action is to launch the Network-AIOps-Workflow in the AAP controller. The entire webhook payload is passed to the workflow as an extra variable named webhook_payload, making the event data available for subsequent automation steps.

== Summary

At this point the EDA rulebook activation history displays that it's listening for ospf webhooks from splunk and waiting for OSPF down messages in the next module.

image::rulebook_history.png[history, 100%]

== Complete

You have completed the EDA setup module. In the next section, we will build on that work by using ‚ú®Lightspeed AI to develop a playbook for OSPF neighbor troubleshooting. This playbook will serve as the automated action for the Splunk and Event-Driven Ansible integration.
